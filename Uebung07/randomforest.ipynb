{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_withfeatures_pandas(dataset_path):\n",
    "    \"\"\"This function loads CSV datasets using the read_csv method of the pandas library.\n",
    "    The CSV is epxected to be comma-separated, while separate examples are separated by new line.\n",
    "    All but the last column are expected to be features, the last columns is parsed as output variable.\"\"\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    X = df.iloc[:, :-1].to_numpy()\n",
    "    y = df.iloc[:, -1].to_numpy()\n",
    "\n",
    "    feature_names = df.iloc[:, :-1].columns.tolist()\n",
    "\n",
    "    return X, y, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_crossval(classifier, X, y, k=10):\n",
    "    \"\"\"Function to evaluate a scikit learn model in 10-fold shuffled\n",
    "    split cross validation. \n",
    "    \"\"\"\n",
    "    # TODO:\n",
    "    # Estimate model performance for given classifier\n",
    "    # Evaluate on k-fold split the validation and train error\n",
    "        # HINT: we are working with classes and classification data\n",
    "        # What does this mean for the cross validation method?\n",
    "    # Return metric for model selection\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_plot_classifer_hyperparams(X, y, classifier, hyperparam_name, hyperparam_values):\n",
    "    \"\"\"Tests different classifiers for different values of a hyper parameter given to the function.\"\"\"\n",
    "\n",
    "    # TODO:\n",
    "    # This is how I have done it, this can possibly be split into two functions\n",
    "    # Carry out accuracy estimation (crossval) on models with different hyperparams\n",
    "    # Plot results against hyperparams\n",
    "    # Don't forget: there are 2 things you need to plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load data\n",
    "# split data\n",
    "# 1.\n",
    "# train decision tree\n",
    "# calc accuracy\n",
    "# 2.\n",
    "# train decision tree\n",
    "# visualize decision tree\n",
    "# 3.\n",
    "# train random forest\n",
    "# calc accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load data\n",
    "# 1.\n",
    "# for different max_depth\n",
    "    # train decision tree\n",
    "    # find out how it performs\n",
    "# plot what you found (max_depth influence)\n",
    "# 2.\n",
    "# for different max_depth\n",
    "    # train random forest classifier\n",
    "    # find out how it performs\n",
    "# plot what you found (max_depth influence)\n",
    "# calc accuracy\n",
    "# 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fc36ab0d55a6a226ae882655424b723ba299a7c7e2b24a1d4fe088de8ed7471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
